{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTU_ML_2019_hw3&4.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqafHEMUdq9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install -q kaggle\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOhho5brhdKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 770 /content/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ybk0dSN6-h3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /root/.kaggle/\n",
        "!cp /content/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYIEZexqfMfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c ml2019spring-hw3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vickgZ5ZI9lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4yy04BEfMcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDnYPiBFRxRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch==1.0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHQDCyZhR8JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import sys ,os\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsxJ3n8c3WqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readfile(path , shuffle):\n",
        "    print(\"Reading File...\")\n",
        "    x_train = []\n",
        "    x_label = []\n",
        "    val_data = []\n",
        "    val_label = []\n",
        "\n",
        "    raw_train = np.genfromtxt(path, delimiter=',', dtype=str, skip_header=1)\n",
        "    for i in range(len(raw_train)):\n",
        "        tmp = np.array(raw_train[i, 1].split(' ') ,dtype =float).reshape(1, 48, 48)\n",
        "        if (i %10 == 0):\n",
        "            val_data.append(tmp)\n",
        "            val_label.append(raw_train[i][0])\n",
        "        else:\n",
        "          # data augmentation\n",
        "            \n",
        "            x_train.append(tmp)\n",
        "            x_train.append(np.flip(tmp, axis=2))    # simple example of data augmentation  fliplr\n",
        "            \n",
        "            noise = np.random.normal(0, 0.03, (1,48,48) )\n",
        "            mask_overflow_upper = tmp+noise >= 1.0\n",
        "            mask_overflow_lower = tmp+noise < 0\n",
        "            noise[mask_overflow_upper] = 1.0\n",
        "            noise[mask_overflow_lower] = 0\n",
        "            x_train.append(tmp)\n",
        "            x_label.append(raw_train[i][0])\n",
        "            \n",
        "            x_label.append(raw_train[i][0])\n",
        "            x_label.append(raw_train[i][0])\n",
        "    \n",
        "    x_train = np.array(x_train, dtype=float) / 255.0\n",
        "    val_data = np.array(val_data, dtype=float) / 255.0\n",
        "    x_label = np.array(x_label, dtype=int)\n",
        "    val_label = np.array(val_label, dtype=int)\n",
        "    x_train = torch.FloatTensor(x_train)\n",
        "    val_data = torch.FloatTensor(val_data)\n",
        "    x_label = torch.LongTensor(x_label)\n",
        "    val_label = torch.LongTensor(val_label)\n",
        "\n",
        "    return x_train, x_label, val_data, val_label\n",
        "\n",
        "x_train, x_label, val_data, val_label = readfile('./train.csv' , shuffle=True)    # 'train.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq2HLBrV3WvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = TensorDataset(x_train, x_label)\n",
        "val_set = TensorDataset(val_data, val_label)\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=32)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIlgYKVw3WtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#baseline cnn\n",
        "def gaussian_weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 and classname.find('Conv') == 0:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.dnn = nn.Sequential(\n",
        "            nn.Linear(48*48*1 , 1024) ,\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "\n",
        "            nn.Linear(1024 , 1024) ,\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            nn.Linear(1024 , 1024) ,\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            nn.Linear(1024 , 1024) ,\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            nn.Linear(1024 , 1024) ,\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "\n",
        "            nn.Linear(1024 , 1024) ,\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "        )\n",
        "\n",
        "        \n",
        "        \n",
        "        self.cnn = nn.Sequential(      # output shape\n",
        "            nn.Conv2d(1, 64, 4 , 2, 1),  # [64, 24, 24]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 64, 3, 1, 1),    # [64, 24,24]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [64, 12, 12]\n",
        "\n",
        "            nn.Conv2d(64, 128, 1, 1, 1),    #[64 , 14 , 14]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 128, 1, 1, 1),    # [64 , 16 , 16]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [128, 8, 8]\n",
        "\n",
        "            nn.Conv2d(128, 256, 1, 1, 1),   # [128, 10, 10]\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256, 256, 1, 1, 1),    #[128,12,12]\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [256, 6, 6]\n",
        "            nn.MaxPool2d(2, 2, 0)       # [256, 3, 3]\n",
        "            \n",
        "        )\n",
        "       \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(256*3*3, 1024), #cnn\n",
        "            #nn.Linear( 1024,1024), #DNN\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 7),\n",
        "        )\n",
        "\n",
        "        self.cnn.apply(gaussian_weights_init)\n",
        "        #self.dnn.apply(gaussian_weights_init)\n",
        "        self.fc.apply(gaussian_weights_init)\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)   # out size = batch size * 256 * 3 * 3 \n",
        "        out = out.view(out.size()[0], -1) # batch size * (256*3*3)\n",
        "        \n",
        "        #x = x.view(x.size()[0],-1)      x.size()[0] = batch size\n",
        "        #out  = self.dnn(x);\n",
        "        return self.fc(out)\n",
        "\n",
        "\n",
        "\n",
        "model = Classifier().cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf7chQ4n2Udy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Construction\n",
        "def gaussian_weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 and classname.find('Conv') == 0:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),  # [64, 48, 48]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0),\n",
        "            nn.Dropout(p=0.3), # [64, 24, 24]\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      \n",
        "            nn.Dropout(p=0.3),   # [128, 12, 12]\n",
        "            \n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      \n",
        "            nn.Dropout(p=0.3),   # [256, 6, 6]\n",
        "            \n",
        "            nn.Conv2d(256, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      \n",
        "            nn.Dropout(p=0.4),   # [512, 3, 3]\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(  #fully connected layers\n",
        "            nn.Linear(512*3*3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 7),\n",
        "        )\n",
        "\n",
        "        self.cnn.apply(gaussian_weights_init)\n",
        "        self.fc.apply(gaussian_weights_init)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)\n",
        "\n",
        "#Training\n",
        "model = Classifier().cuda()\n",
        "# print(model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4P-sfMmjqPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def gaussian_weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 and classname.find('Conv') == 0:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,inchannel , outchannel,stride = 1):\n",
        "      super(ResidualBlock ,self).__init__()\n",
        "      '''\n",
        "      self.left = nn.Sequential(\n",
        "          nn.Conv2d(inchannel ,outchannel,kernel_size = 3,stride =stride,padding=1),\n",
        "          nn.BatchNorm2d(outchannel),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(outchannel ,outchannel,kernel_size = 3,stride =1,padding=1),\n",
        "          nn.BatchNorm2d(outchannel)\n",
        "      )\n",
        "      '''\n",
        "      self.left = nn.Sequential(\n",
        "          nn.Conv2d(inchannel ,outchannel,kernel_size = 1,stride =1,padding=0),\n",
        "          nn.BatchNorm2d(outchannel),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(outchannel ,outchannel,kernel_size = 3,stride =stride,padding=1),\n",
        "          nn.BatchNorm2d(outchannel),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(outchannel ,outchannel,kernel_size = 1,stride =1,padding=0),\n",
        "          nn.BatchNorm2d(outchannel),\n",
        "      )\n",
        "      \n",
        "      self.shortcut = nn.Sequential()\n",
        "      if stride != 1 or inchannel != outchannel:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResidualBlock,num_classes = 7):\n",
        "      super(ResNet , self).__init__()\n",
        "      self.inchannel = 64\n",
        "      self.conv1 = nn.Sequential(\n",
        "          nn.Conv2d(1 ,64,kernel_size=3,stride=1,padding =1),  # 64 * 48, 48 \n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(),\n",
        "      )\n",
        "      self.layer1 = self._layer_(ResidualBlock , 64,2,stride = 1)  # [64* 32* 32]\n",
        "      self.layer2 = self._layer_(ResidualBlock , 128,2,stride = 2)  #[ 64, /2,/2]\n",
        "      self.layer3 = self._layer_(ResidualBlock , 256,2,stride = 2)\n",
        "      self.layer4 = self._layer_(ResidualBlock , 512,2,stride = 2)\n",
        "      self.fc = nn.Linear(512,num_classes)\n",
        "    def _layer_(self, block , channels , num_blocks  , stride):\n",
        "      strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
        "      layers = []\n",
        "      for stride in strides:\n",
        "          layers.append(block(self.inchannel, channels, stride))\n",
        "          self.inchannel = channels\n",
        "      return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "      out = self.conv1(x)\n",
        "      out = self.layer1(out)\n",
        "      out = self.layer2(out)\n",
        "      out = self.layer3(out)\n",
        "      out = self.layer4(out)\n",
        "      out = F.avg_pool2d(out, 4)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "def ResNet18():\n",
        "\n",
        "    return ResNet(ResidualBlock)\n",
        "\n",
        "model = ResNet18().cuda()\n",
        "#print(model)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUCfo5MT3d-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(model)\n",
        "#model = ResNet18().cuda()\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "best_acc = 0.0\n",
        "num_epoch = 50\n",
        "val_acc_ = []\n",
        "train_acc_ = []\n",
        "model_path = '/content/drive/My'' ''Drive/Colab_model/'\n",
        "if os.path.isfile(model_path+'model_cnn'):\n",
        "    model.load_state_dict(torch.load(model_path+'model_cnn'))\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        train_pred = model(data[0].cuda())\n",
        "        batch_loss = loss(train_pred, data[1].cuda())\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        \n",
        "        train_loss += batch_loss.item()\n",
        "        progress = ('#' * int(float(i)/len(train_loader)*40)).ljust(40)\n",
        "        print ('[%03d/%03d] %2.2f sec(s) | %s |' % (epoch+1, num_epoch, \\\n",
        "                (time.time() - epoch_start_time), progress), end='\\r', flush=True)\n",
        "    \n",
        "    model.eval()\n",
        "    for i, data in enumerate(val_loader):\n",
        "        val_pred = model(data[0].cuda())\n",
        "        batch_loss = loss(val_pred, data[1].cuda())\n",
        "\n",
        "        val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        \n",
        "        val_loss += batch_loss.item()\n",
        "\n",
        "        progress = ('#' * int(float(i)/len(val_loader)*40)).ljust(40)\n",
        "        print ('[%03d/%03d] %2.2f sec(s) | %s |' % (epoch+1, num_epoch, \\\n",
        "                (time.time() - epoch_start_time), progress), end='\\r', flush=True)\n",
        "\n",
        "    val_acc = val_acc/val_set.__len__()\n",
        "    train_acc = train_acc/train_set.__len__()\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "             train_acc, train_loss, val_acc, val_loss))\n",
        "\n",
        "    train_acc_.append(train_acc)\n",
        "    val_acc_.append(val_acc)\n",
        "\n",
        "    if (val_acc > best_acc):\n",
        "        with open('./acc.txt','w') as f:\n",
        "            f.write(str(epoch)+'\\t'+str(val_acc)+'\\n')\n",
        "        torch.save(model.state_dict(), model_path+'model_cnn')\n",
        "        best_acc = val_acc\n",
        "        print ('Model Saved!')\n",
        "\n",
        "plt.plot(np.arange(num_epoch),np.expand_dims(train_acc_ ,axis= 1) )\n",
        "plt.plot(np.arange(num_epoch),np.expand_dims(val_acc_ , axis = 1) )\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgqRqOzN3eDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_result=[]\n",
        "x_test=[]\n",
        "raw_test = np.genfromtxt('./test.csv' , delimiter=',', dtype=str, skip_header=1)\n",
        "for i in range(len(raw_test)):\n",
        "  tmp = np.array(raw_test[i,1].split(' ')).reshape(1,48,48)\n",
        "  tmp =  np.array(tmp , dtype=float)/255.0  \n",
        "  x_test.append(tmp)\n",
        "\n",
        "x_test = torch.FloatTensor(  x_test )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8FTkUQrbNZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_result=[]\n",
        "bz = 32\n",
        "for i in range(1+x_test.shape[0]//bz):\n",
        "  if i==x_test.shape[0]//bz:\n",
        "    x_pred = model(x_test[i*bz:].cuda())\n",
        "    x_result.extend(np.argmax(x_pred.cpu().data.numpy(), axis=1) )\n",
        "    break\n",
        "  x_pred = model(x_test[i*bz:(i+1)*bz].cuda())\n",
        "  x_result.extend(np.argmax(x_pred.cpu().data.numpy(), axis=1) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqIoQetEbGXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "if os.path.isfile('./output.csv'):\n",
        "    os.remove('./output.csv')\n",
        "with open('./output.csv',\"w\") as f:\n",
        "  w = csv.writer(f)\n",
        "  title = ['id','label']\n",
        "  w.writerow(title) \n",
        "  for i in range(len(x_result)):\n",
        "      content = [str(i),str(x_result[i]) ]\n",
        "      \n",
        "      w.writerow(content) \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBQmIyKe3d6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5pCv1CFcGGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readfile(path , shuffle):\n",
        "    print(\"Reading File...\")\n",
        "    x_train = []\n",
        "    x_label = []\n",
        "    val_data = []\n",
        "    val_label = []\n",
        "\n",
        "    raw_train = np.genfromtxt(path, delimiter=',', dtype=str, skip_header=1)\n",
        "    for i in range(len(raw_train)):\n",
        "        tmp = np.array(raw_train[i, 1].split(' ') ,dtype =float).reshape(1, 48, 48)\n",
        "        if (i %10 == 0):\n",
        "            val_data.append(tmp)\n",
        "            val_label.append(raw_train[i][0])\n",
        "        else:\n",
        "          # data augmentation\n",
        "            \n",
        "            x_train.append(tmp)\n",
        "            x_train.append(np.flip(tmp, axis=2))    # simple example of data augmentation  fliplr\n",
        "            \n",
        "            noise = np.random.normal(0, 0.03, (1,48,48) )\n",
        "            mask_overflow_upper = tmp+noise >= 1.0\n",
        "            mask_overflow_lower = tmp+noise < 0\n",
        "            noise[mask_overflow_upper] = 1.0\n",
        "            noise[mask_overflow_lower] = 0\n",
        "            x_train.append(tmp)\n",
        "            x_label.append(raw_train[i][0])\n",
        "            \n",
        "            x_label.append(raw_train[i][0])\n",
        "            x_label.append(raw_train[i][0])\n",
        "    \n",
        "    x_train = np.array(x_train, dtype=float) / 255.0\n",
        "    val_data = np.array(val_data, dtype=float) / 255.0\n",
        "    x_label = np.array(x_label, dtype=int)\n",
        "    val_label = np.array(val_label, dtype=int)\n",
        "    x_train = torch.FloatTensor(x_train)\n",
        "    val_data = torch.FloatTensor(val_data)\n",
        "    x_label = torch.LongTensor(x_label)\n",
        "    val_label = torch.LongTensor(val_label)\n",
        "\n",
        "    return x_train, x_label, val_data, val_label\n",
        "\n",
        "x_train, x_label, val_data, val_label = readfile('./train.csv' , shuffle=True)    # 'train.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL3aoo0FcGDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Classifier()\n",
        "model_path = '/content/drive/My'' ''Drive/Colab_model/model_cnn'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gHRQdyKct9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_saliency_maps(x, y, model):\n",
        "    model.eval()\n",
        "    x.requires_grad_()\n",
        "    y_pred = model(x.cuda())\n",
        "    loss_func = torch.nn.CrossEntropyLoss()\n",
        "    loss = loss_func(y_pred, y.cuda())\n",
        "    loss.backward()\n",
        "\n",
        "    saliency = x.grad.abs().squeeze().data\n",
        "    return saliency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTghtisyCg6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saliency.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16A0ZuyPByK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_img = x_train[:1].squeeze().numpy()\n",
        "saliency = compute_saliency_maps(x_train[:1], x_label[:1], model)\n",
        "saliency = saliency.detach().cpu().numpy()\n",
        "plt.imshow(x_img, cmap=plt.cm.gray)\n",
        "plt.show()\n",
        "plt.imshow(saliency, cmap=plt.cm.jet)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX5R80l3cuDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_saliency_maps(x, y, model):\n",
        "    x_org = x.squeeze().numpy()\n",
        "    # Compute saliency maps for images in X\n",
        "    saliency = compute_saliency_maps(x, y, model)\n",
        "\n",
        "    # Convert the saliency map from Torch Tensor to numpy array and show images\n",
        "    # and saliency maps together.\n",
        "    saliency = saliency.detach().cpu().numpy()\n",
        "    num_pics = x_org.shape[0]\n",
        "    print(num_pics)\n",
        "    \n",
        "    for i in range(num_pics):\n",
        "        # You need to save as the correct fig names\n",
        "        plt.imshow(x_org[i], cmap=plt.cm.gray)\n",
        "        plt.show()\n",
        "        plt.imshow(saliency[i], cmap=plt.cm.jet)\n",
        "        plt.show()\n",
        "        #plt.imsave('p3/pic_'+ str(i), x_org[i], cmap=plt.cm.gray)\n",
        "        #plt.imsave('p3/saliency_'+ str(i), saliency[i], cmap=plt.cm.jet)\n",
        "    \n",
        "# using the first ten images for example\n",
        "show_saliency_maps(x_train[:5], x_label[:5], model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SchtspoWcuA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install lime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1d1YT13skkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import slic\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import skimage\n",
        "from skimage.segmentation import mark_boundaries\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FEuWx3jt6A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(7):\n",
        "    for j in range(700):\n",
        "        if(x_label[j]==i):\n",
        "            plt.imshow(x_train[j][0], cmap=plt.cm.gray)\n",
        "            plt.show()\n",
        "            print(x_label[j])\n",
        "            print(i , j)\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll_wIqbrfoYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# load data and model\n",
        "#x_train = torch.load('data/train_data.pth')\n",
        "#x_label = torch.load('data/train_label.pth')\n",
        "\n",
        "# Lime needs RGB images\n",
        "# TODO:\n",
        "\n",
        "#x_train_rgb = torch.FloatTensor(  x_train_rgb )\n",
        "\n",
        "\n",
        "# x_train_rgb = ?\n",
        "\n",
        "model = Classifier()\n",
        "model_path = '/content/drive/My'' ''Drive/Colab_model/model_cnn'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# two functions that lime image explainer requires\n",
        "def predict(input):\n",
        "    # Input: image tensor\n",
        "    # Returns a predict function which returns the probabilities of labels ((7,) numpy array)\n",
        "    # ex: return model(data).numpy()\n",
        "    # TODO:\n",
        "    model.eval().cuda()\n",
        "    input = input.swapaxes(-1,-2)\n",
        "    input = torch.FloatTensor(  input.swapaxes(-3,-2) )\n",
        "    #print(input.shape , input.dtype)\n",
        "    logits = model(input[:,:1,:,:].cuda())\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    return probs.detach().cpu().numpy()\n",
        "    \n",
        "    # return ?\n",
        "\n",
        "def segmentation(input):\n",
        "    # Input: image numpy array\n",
        "    # Returns a segmentation function which returns the segmentation labels array ((48,48) numpy array)\n",
        "    # ex: return skimage.segmentation.slic()\n",
        "    # TODO:\n",
        "    # return ?\n",
        "\n",
        "    return skimage.segmentation.slic(input)\n",
        "\n",
        "# Initiate explainer instance\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "# Get the explaination of an image\n",
        "\n",
        "for idx in range(10):\n",
        "    #x_train_rgb = np.zeros([3,48,48])\n",
        "    #x_train_rgb[0,:,:] = x_train[idx][0].data\n",
        "    #x_train_rgb[1,:,:] = x_train[idx][0].data\n",
        "    #x_train_rgb[2,:,:] = x_train[idx][0].data\n",
        "\n",
        "    explaination = explainer.explain_instance(\n",
        "                                image=np.array(x_train[idx].squeeze()  , dtype = float), \n",
        "                                classifier_fn=predict,\n",
        "                                segmentation_fn=segmentation\n",
        "                            )\n",
        "\n",
        "    # Get processed image\n",
        "    image, mask = explaination.get_image_and_mask(\n",
        "                                    label=int(x_label[idx]),\n",
        "                                    positive_only=False,\n",
        "                                    hide_rest=False,\n",
        "                                    num_features=5,\n",
        "                                    min_weight=0.0\n",
        "                                )\n",
        "    img_boundry1 = mark_boundaries(image, mask)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    plt.imshow(img_boundry1)\n",
        "    plt.show()\n",
        "# save the image\n",
        "#plt.imsave('img', image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXKa6ThMYVK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}